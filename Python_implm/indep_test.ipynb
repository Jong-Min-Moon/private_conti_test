{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "36b7f28c-36fb-4175-961c-76fdad718dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import itertools\n",
    "from scipy.special import comb\n",
    "\n",
    "class LDPIndepTester:\n",
    "    def __init__(self, cuda_device):\n",
    "        self.cuda_device = cuda_device\n",
    "\n",
    "   \n",
    "    def bin_separately(self, data_X, data_Y, kappa):\n",
    "        return (\n",
    "            self.bin(data_X, kappa),\n",
    "            self.bin(data_Y, kappa)\n",
    "            )\n",
    "\n",
    "        \n",
    "    def range_check(self, data):\n",
    "        if (torch.sum(data.gt(1))).gt(0):\n",
    "            print(\"check data range\")\n",
    "            return False\n",
    "        elif (torch.sum(data.le(0))).gt(0):\n",
    "            print(\"check data range\")\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def run_test_conti_data(self, B, data_Y, data_Z, kappa, alpha, gamma, discrete_noise = False):\n",
    "        #0. data range check\n",
    "        \n",
    "        if not self.range_check(data_Y):\n",
    "            return\n",
    "        if not self.range_check(data_Z):\n",
    "            return\n",
    "        \n",
    "        #1. bin\n",
    "        n = data_Y.size(dim = 0)\n",
    "        data_Y_binned, data_Z_binned = self.bin_separately(data_Y, data_Z, kappa)\n",
    "\n",
    "        #2. privatize\n",
    "        data_Y_priv, data_Z_priv, noise_var_Y, noise_var_Z = self.privatize_indep(\n",
    "            data_Y = data_Y,\n",
    "            data_Z = data_Z,\n",
    "            alpha = alpha,\n",
    "            discrete_noise = discrete_noise\n",
    "        )\n",
    "        \n",
    "        #4 compute original u-stat\n",
    "        ustatOriginal = self.u_stat_indep_matrix(data_Y_priv, data_Z_priv)\n",
    "\n",
    "        print(f\"original u-statistic:{ustatOriginal}\")\n",
    "        \n",
    "        #permutation procedure\n",
    "        permStats = torch.empty(B).to(self.cuda_device)\n",
    "        \n",
    "        for i in range(B):\n",
    "            perm_stat_now = self.u_stat_indep_matrix(\n",
    "                data_Y_priv,\n",
    "                data_Z_priv[\n",
    "                    torch.randperm(data_Z_priv.size(dim=0))],\n",
    "                ).to(self.cuda_device)\n",
    "\n",
    "            permStats[i] = perm_stat_now\n",
    "            #print(perm_stat_now)\n",
    "         \n",
    "        \n",
    "        p_value_proxy = (1 +\n",
    "                         torch.sum(\n",
    "                             torch.gt(input = permStats, other = ustatOriginal)\n",
    "                         )\n",
    "                        ) / (B + 1)\n",
    "        \n",
    "        \n",
    "        print(f\"p value proxy: {p_value_proxy}\")\n",
    "        \n",
    "        return(p_value_proxy < gamma, noise_var_Y, noise_var_Z)#test result: TRUE = 1 = reject the null, FALSE = 0 = retain the null.\n",
    "\n",
    "        \n",
    "    def privatize_indep(self, data_Y, data_Z, alpha = float(\"inf\"), discrete_noise = False):\n",
    "        ## assume the data is discrete by nature or has already been dicretized.\n",
    "        n = data_Y.size(dim = 0) # Y and Z have the same sample size.\n",
    "        kappa_d1 = data_Y.size(dim = 1) #kappa^d if conti data, d if discrete data\n",
    "        kappa_d2 = data_Z.size(dim = 1) #kappa^d if conti data, d if discrete data\n",
    "\n",
    "        print(f\"noise dimension : {kappa_d1}, {kappa_d2}\")\n",
    "        \n",
    "        scale_factor = torch.tensor( (kappa_d1 * kappa_d2)**(1/2) )\n",
    "        sigma_kappa_alpha = 4 * (2 ** (1/2)) * scale_factor / alpha\n",
    "        \n",
    "        if alpha == float(\"inf\"): #non-private case\n",
    "            return( torch.mul(scale_factor, data) )\n",
    "        else:\n",
    "            data_Y_priv, noise_var_Y = self.privatize_indep_separate(\n",
    "                    data = data_Y,\n",
    "                    scale_factor = scale_factor,\n",
    "                    sigma_kappa_alpha = sigma_kappa_alpha,\n",
    "                    discrete_noise = discrete_noise\n",
    "            )\n",
    "            data_Z_priv, noise_var_Z = self.privatize_indep_separate(\n",
    "                    data = data_Z,\n",
    "                    scale_factor = scale_factor,\n",
    "                    sigma_kappa_alpha = sigma_kappa_alpha,\n",
    "                    discrete_noise = discrete_noise\n",
    "            )\n",
    "        return(data_Y_priv, data_Z_priv, noise_var_Y, noise_var_Z)\n",
    "        \n",
    "    \n",
    "    def privatize_indep_separate(self, data, scale_factor, sigma_kappa_alpha, discrete_noise):\n",
    "        n = data.size(dim = 0)\n",
    "        if discrete_noise:\n",
    "            noise, noise_var = self.noise_conti(data, sigma_kappa_alpha) #fix here later\n",
    "        else:\n",
    "            noise, noise_var = self.noise_conti(data, sigma_kappa_alpha)\n",
    "        return(   \n",
    "            torch.add(\n",
    "                input = noise.reshape(n, -1),\n",
    "                alpha = scale_factor,\n",
    "                other = data\n",
    "            ), \n",
    "            noise_var\n",
    "        )\n",
    "                       \n",
    "    def noise_conti(self, data, sigma_kappa_alpha):\n",
    "        #dim = kappa^d for conti data, d for discrete data\n",
    "        laplace_samples = self.generate_unit_laplace(data)\n",
    "        laplace_samples = sigma_kappa_alpha * laplace_samples\n",
    "        print(\"noise type: conti\")\n",
    "        return( laplace_samples, torch.var(laplace_samples) )\n",
    "    \n",
    "\n",
    "    def generate_unit_laplace(self, data):\n",
    "        n = data.size(dim = 0)\n",
    "        d = data.size(dim = 1)\n",
    "        unit_laplace_generator = torch.distributions.laplace.Laplace(\n",
    "            torch.tensor(0.0).to(self.cuda_device),\n",
    "            torch.tensor(2**(-1/2)).to(self.cuda_device)\n",
    "        )\n",
    "        return unit_laplace_generator.sample(sample_shape = torch.Size([n * d]))\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "################# For binning ############################################################\n",
    "##########################################################################################\n",
    "    def bin(self, data, kappa): \n",
    "        ''' Only for continuous data'''\n",
    "        \n",
    "        # create designated number of intervals\n",
    "        d = self.get_dimension(data)\n",
    "        print(d)\n",
    "     \n",
    "        # 1. for each dimension, turn the continuous data into interval\n",
    "        # each row now indicates a hypercube in [0,1]^d\n",
    "        # the more the data is closer to 1, the larger the interval index.\n",
    "        dataInterval = self.transform_bin_index(data = data, nIntervals = kappa)\n",
    "        \n",
    "        # 2. for each datapoint(row),\n",
    "        #    turn the hypercube data into a multivariate data of (1, 2, ..., kappa^d)\n",
    "        #    each row now becomes an integer.\n",
    "        dataMultivariate = self.TransformMultivariate(\n",
    "            dataInterval = dataInterval,\n",
    "            nBin = kappa,\n",
    "        )\n",
    "        # 3. turn the indices into one-hot vectors\n",
    "        dataOnehot = self.TransformOnehot(dataMultivariate, kappa**d)\n",
    "        return(dataOnehot)\n",
    "    \n",
    "    def transform_bin_index(self, data, nIntervals):\n",
    "        ''' Only for continuous data.\n",
    "        for each dimension, transform the data in [0,1] into the interval index\n",
    "        first interval = [0, x], the others = (y z]\n",
    "        \n",
    "        input arguments\n",
    "            data: torch tensor object on GPU\n",
    "            nIntervals: integer\n",
    "        output\n",
    "            dataIndices: torch tensor, dimension same as the input\n",
    "        '''\n",
    "        # create designated number of intervals\n",
    "        d = self.get_dimension(data)\n",
    "        breaks = torch.linspace(start = 0, end = 1, steps = nIntervals + 1).to(self.cuda_device) #floatTensor\n",
    "        dataIndices = torch.bucketize(data, breaks, right = False) # ( ] form.\n",
    "        dataIndices = dataIndices.add(\n",
    "            dataIndices.eq(0)\n",
    "        ) #move 0 values from the bin number 0 to the bin number 1        \n",
    "        return(dataIndices)\n",
    "    \n",
    "    def TransformMultivariate(self, dataInterval, nBin):\n",
    "        \"\"\"Only for continuous and multivariate data .\"\"\"\n",
    "        d = self.get_dimension(dataInterval)\n",
    "        \n",
    "        if d == 1:\n",
    "            return(dataInterval.sub(1))\n",
    "        else:\n",
    "            exponent = torch.linspace(start = (d-1), end = 0, steps = d, dtype = torch.long)\n",
    "            vector = torch.tensor(nBin).pow(exponent)\n",
    "            return( torch.matmul( dataInterval.sub(1).to(torch.float), vector.to(torch.float).to(self.cuda_device) ).to(torch.long) )\n",
    "    \n",
    "    def TransformOnehot(self, dataMultivariate, newdim):\n",
    "        return(\n",
    "            torch.nn.functional.one_hot(\n",
    "                dataMultivariate,\n",
    "                num_classes = newdim)\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def get_dimension(self, data):\n",
    "        if data.dim() == 1:\n",
    "            return(1)\n",
    "        elif data.dim() == 2:\n",
    "            return( data.size(dim = 1) )\n",
    "        else:\n",
    "            return # we only use up to 2-dimensional tensor, i.e. matrix\n",
    "##########################################################################################\n",
    "##########################################################################################\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    def kernel_indep(self, fourchunk):\n",
    "        ip = torch.matmul(fourchunk, torch.transpose(fourchunk, 0, 1))\n",
    "        return(ip[0,1] + ip[2,3] - ip[0,2] - ip[1,3])\n",
    "\n",
    "     \n",
    "    def u_stat_indep_matrix(self, data_X, data_Y):\n",
    "        n = data_X.size(dim=0)\n",
    "        Phi = torch.matmul(data_X, torch.transpose(data_X, 0, 1))\n",
    "        Psi = torch.matmul(data_Y, torch.transpose(data_Y, 0, 1))\n",
    "        Phi_tilde = Phi.fill_diagonal_(0.0)\n",
    "        Psi_tilde = Psi.fill_diagonal_(0.0)\n",
    "        n_four = n * (n-1) * (n-2) * (n-3)\n",
    "        one = torch.ones(n, 1).to(device)\n",
    "        oneT = torch.transpose(one, 0, 1)\n",
    "\n",
    "        PhiPsi = torch.matmul(Phi, Psi)\n",
    "        trPhiPsi = torch.trace(PhiPsi)\n",
    "        onePhiPsiOne = torch.matmul(oneT, torch.matmul(PhiPsi, one))\n",
    "\n",
    "        onePhione = torch.matmul(oneT, torch.matmul(Phi, one))\n",
    "        onePsione = torch.matmul(oneT, torch.matmul(Psi, one))\n",
    "        onePhioneonePsione = torch.matmul(onePhione, onePsione)\n",
    "\n",
    "        Un = (\n",
    "          4 * (onePhioneonePsione - 4 * onePhiPsiOne + 2 * trPhiPsi)\n",
    "        - 8 * (n-3) *(onePhiPsiOne - trPhiPsi)\n",
    "        + 4 * (n-3)*(n-2) * trPhiPsi\n",
    "        )\n",
    "        \n",
    "        return(Un/n_four)\n",
    "    \n",
    "    def u_stat_indep_original(self, data_X, data_Y):\n",
    "        n = data_X.size(dim = 0)\n",
    "        print(f\"number of calculation = {2*scipy.special.comb(n,4) }\")\n",
    "        n_four = n * (n-1) * (n-2) * (n-3)\n",
    "        U_statistic = 0\n",
    "        for i in range(n):\n",
    "            set_j = set(range(n)) - {i}\n",
    "            for j in set_j:\n",
    "                set_k = set_j - {j}\n",
    "                for k in set_k:\n",
    "                    set_r = set_k - {k}\n",
    "                    for r in set_r:\n",
    "                        comb = [i,j,k,r]\n",
    "                        U_statistic = U_statistic + (\n",
    "                            self.kernel_indep(data_X[comb,]) * self.kernel_indep(data_Y[comb,])\n",
    "                        )/n_four\n",
    "        return(U_statistic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "35631ed7-dd6d-4259-9666-a81b71ecbe95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "noise dimension : 2, 2\n",
      "noise type: conti\n",
      "noise type: conti\n",
      "original u-statistic:tensor([[-2381.4062]], device='cuda:1')\n",
      "p value proxy: 0.8272424936294556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(False, device='cuda:1'),\n",
       " tensor(482.5581, device='cuda:1'),\n",
       " tensor(493.8383, device='cuda:1'))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "device = torch.device('cuda:1')\n",
    "\n",
    "n= 1000\n",
    "d = 2\n",
    "loc = torch.zeros(d)\n",
    "scale = torch.ones(d)*2\n",
    "mvn1 = torch.distributions.MultivariateNormal(loc, scale_tril=torch.diag(scale))\n",
    "mvn2 = torch.distributions.MultivariateNormal(loc, scale_tril=torch.diag(scale))\n",
    "\n",
    "data_Y = mvn1.sample(sample_shape=torch.Size([n])).to(device)\n",
    "data_Y = data_Y.abs() / data_Y.abs().max()\n",
    "\n",
    "data_Z = mvn2.sample(sample_shape=torch.Size([n])).to(device)\n",
    "data_Z = data_Z.abs() / data_Z.abs().max()\n",
    "\n",
    "tester = LDPIndepTester(device)\n",
    "tester.run_test_conti_data(B = 300, data_Y = data_Y, data_Z = data_Z, kappa = 3, alpha = 0.5, gamma = 0.05, discrete_noise = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8d582e-4cbc-4ef5-814d-0cb25744e49a",
   "metadata": {},
   "source": [
    "dependent case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "42fe74d1-7e8b-401d-8c9c-928901ad3879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "noise dimension : 2, 2\n",
      "noise type: conti\n",
      "noise type: conti\n",
      "original u-statistic:tensor([[-15337.7109]], device='cuda:1')\n",
      "p value proxy: 0.6810631155967712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(False, device='cuda:1'),\n",
       " tensor(184.5706, device='cuda:1'),\n",
       " tensor(100.3413, device='cuda:1'))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "device = torch.device('cuda:1')\n",
    "\n",
    "n= 10\n",
    "d = 2\n",
    "loc = torch.zeros(d)\n",
    "scale = torch.ones(d)*2\n",
    "mvn1 = torch.distributions.MultivariateNormal(loc, scale_tril=torch.diag(scale))\n",
    "mvn2 = torch.distributions.MultivariateNormal(loc, scale_tril=torch.diag(scale))\n",
    "\n",
    "data_Y = mvn1.sample(sample_shape=torch.Size([n])).to(device)\n",
    "data_Y = data_Y.abs() / data_Y.abs().max()\n",
    "\n",
    "data_Z = data_Y\n",
    "\n",
    "tester = LDPIndepTester(device)\n",
    "tester.run_test_conti_data(B = 300, data_Y = data_Y, data_Z = data_Z, kappa = 3, alpha = 1, gamma = 0.05, discrete_noise = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "03ff0ab6-f363-4f79-90b2-c396d67faee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0670, 0.0777],\n",
       "        [0.1383, 0.5785],\n",
       "        [0.0628, 0.2662]], device='cuda:1')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Y[[1,3,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dea49d34-4934-47cb-8357-6dd5e542fcab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1953, 0.3120],\n",
       "        [0.1027, 0.2393],\n",
       "        [0.0016, 0.1836]], device='cuda:1')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Y[[1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a7231722-322d-4d26-b1b8-1e1f3316c2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1848, 0.1545],\n",
       "        [0.1953, 0.3120],\n",
       "        [0.1027, 0.2393],\n",
       "        ...,\n",
       "        [0.0226, 0.4141],\n",
       "        [0.2555, 0.2850],\n",
       "        [0.4730, 0.1915]], device='cuda:1')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "21cc0c97-de64-4518-be8a-7b9fc7debd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[20.6667]], device='cuda:1')\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LDPIndepTester' object has no attribute 'u_stat_indep'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [181]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m data_Y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtranspose(torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m11.0\u001b[39m,\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m13\u001b[39m,\u001b[38;5;241m14\u001b[39m,\u001b[38;5;241m15\u001b[39m]]), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(matrix_form(data_X, data_Y))\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtester\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mu_stat_indep\u001b[49m(data_X, data_Y)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LDPIndepTester' object has no attribute 'u_stat_indep'"
     ]
    }
   ],
   "source": [
    "data_X = torch.transpose(torch.tensor([[1.0,2,3,4,5]]), 0, 1).to(device)\n",
    "data_Y = torch.transpose(torch.tensor([[11.0,12,13,14,15]]), 0, 1).to(device)\n",
    "print(matrix_form(data_X, data_Y))\n",
    "tester.u_stat_indep(data_X, data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c2142e11-c603-4a80-9311-a86eb655c83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.]], device='cuda:1')\n",
      "number of calculation = 10.0\n",
      "tensor(0., device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "data_X = torch.ones(10,3).to(device)\n",
    "data_Y = data_X\n",
    "print(matrix_form(data_X, data_Y))\n",
    "tester = LDPIndepTester(device)\n",
    "tester.u_stat_indep(data_X, data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5c5a2cc1-baf6-4ca0-9790-f74340b405d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.2857]], device='cuda:1')\n",
      "number of calculation = 140.0\n",
      "tensor(5.2857, device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "data_X = torch.transpose(torch.tensor([[1.0, 1, 1, 1, 1,2,3,4]]), 0, 1).to(device)\n",
    "data_Y = data_X\n",
    "print(matrix_form(data_X, data_Y))\n",
    "print(tester.u_stat_indep(data_X, data_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e0592483-de55-4b60-9a0e-78c6880c2bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[26567.0859]], device='cuda:1')\n",
      "number of calculation = 140.0\n",
      "tensor(26567.1289, device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "data_X = torch.transpose(torch.tensor([\n",
    "    [1.0, 12, 1, 1, 1,22,3,4],[1.0, 12, 1, 1, 1,22,3,4]]\n",
    "), 0, 1).to(device)\n",
    "data_Y = data_X-1\n",
    "print(matrix_form(data_X, data_Y))\n",
    "print(tester.u_stat_indep(data_X, data_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "633a2bf5-5b46-489e-a4ee-c74e41068369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6293.0815]], device='cuda:1')\n",
      "number of calculation = 3640.0\n",
      "tensor(6293.6973, device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "data_X = torch.transpose(torch.tensor([[1.0, 12, 1, 1, 1,12,33,2,1,3,4,5,7,4,5,3]]), 0, 1).to(device)\n",
    "data_Y = data_X-10.0\n",
    "print(matrix_form(data_X, data_Y))\n",
    "print(tester.u_stat_indep(data_X, data_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a1e321-4ebf-49b8-b7e3-53eb5012e6ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
