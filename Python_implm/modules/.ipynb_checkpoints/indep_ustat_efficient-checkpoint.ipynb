{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available: True\n",
      "code run on device:: cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available() \n",
    "print(f\"cuda available: {USE_CUDA}\")\n",
    "\n",
    "device = torch.device('cuda:1' if USE_CUDA else 'cpu') \n",
    "print(f\"code run on device:: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def u_stat_indep_matrix(self, data_X, data_Y):\n",
    "    n = data_X.size(dim=0)\n",
    "\n",
    "    Phi = torch.matmul(data_X, torch.transpose(data_X, 0, 1))\n",
    "    Psi = torch.matmul(data_Y, torch.transpose(data_Y, 0, 1))\n",
    "    \n",
    "    Phi_tilde = Phi.fill_diagonal_(0.0)\n",
    "    Psi_tilde = Psi.fill_diagonal_(0.0)\n",
    "    \n",
    "    n_four = n * (n-1) * (n-2) * (n-3)\n",
    "    one = torch.ones(n, 1).to(device)\n",
    "    oneT = torch.transpose(one, 0, 1)\n",
    "\n",
    "    PhiPsi = torch.matmul(Phi, Psi)\n",
    "    trPhiPsi = torch.trace(PhiPsi)\n",
    "    onePhiPsiOne = torch.matmul(oneT, torch.matmul(PhiPsi, one))\n",
    "\n",
    "    onePhione = torch.matmul(oneT, torch.matmul(Phi, one))\n",
    "    onePsione = torch.matmul(oneT, torch.matmul(Psi, one))\n",
    "    onePhioneonePsione = torch.matmul(onePhione, onePsione)\n",
    "\n",
    "    Un = (\n",
    "          4 * (onePhioneonePsione - 4 * onePhiPsiOne + 2 * trPhiPsi)\n",
    "        - 8 * (n-3) *(onePhiPsiOne - trPhiPsi)\n",
    "        + 4 * (n-3)*(n-2) * trPhiPsi\n",
    "        )\n",
    "        \n",
    "    return(Un/n_four)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. verification of simplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3840\n",
      "3840\n"
     ]
    }
   ],
   "source": [
    "onePhioneonePsione = 10\n",
    "onePhiPsiOne = 2\n",
    "trPhiPsi = 3\n",
    "n = 20\n",
    "\n",
    "print(\n",
    "          4 * (onePhioneonePsione - 4 * onePhiPsiOne + 2 * trPhiPsi)\n",
    "        - 8 * (n-3) *(onePhiPsiOne - trPhiPsi)\n",
    "        + 4 * (n-3)*(n-2) * trPhiPsi\n",
    "        )\n",
    "\n",
    "print(\n",
    "          4 * onePhioneonePsione\n",
    "        - 8 * (n-1) * onePhiPsiOne\n",
    "        + 4 * (n-1) * (n-2) * trPhiPsi\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. verification of tr(phi psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = torch.normal(0,1, [5000,9]).to(device)\n",
    "data_Y = torch.normal(0,1, [5000,9]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:1')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#einsum verification\n",
    "# XtX\n",
    "Phi_einsum = torch.einsum('ji,jk->ik', data_X, data_X)\n",
    "Phi_matmul = torch.matmul(torch.transpose(data_X, 0, 1), data_X)\n",
    "Phi_einsum - Phi_matmul\n",
    "#success\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:1')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#einsum verification\n",
    "# XXt\n",
    "Phi_einsum = torch.einsum('ij,kj->ik', data_X, data_X)\n",
    "Phi_matmul = torch.matmul(data_X, torch.transpose(data_X, 0, 1))\n",
    "Phi_einsum - Phi_matmul\n",
    "#success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(301518.5625, device='cuda:1')\n",
      "tensor(301518.5625, device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "# transpose verification\n",
    "data_X = torch.normal(0,1, [5000,9]).to(device)\n",
    "data_Y = torch.normal(0,1, [5000,9]).to(device)\n",
    "\n",
    "Phi = torch.einsum('ij,kj->ik', data_X, data_X)\n",
    "Psi = torch.einsum('ij,kj->ik', data_Y, data_Y)\n",
    "tr_matmul = torch.trace(torch.matmul(Phi, Psi))\n",
    "tr_sumsq = torch.sum(\n",
    "    torch.square(\n",
    "        torch.einsum('ji,jk->ik', data_X, data_Y)\n",
    "    )\n",
    ")\n",
    "print(tr_matmul)\n",
    "print(tr_sumsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4756153., device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "# transpose verification on large size\n",
    "data_X = torch.normal(0,1, [50000,9]).to(device)\n",
    "data_Y = torch.normal(0,1, [50000,9]).to(device)\n",
    "\n",
    "\n",
    "tr_sumsq = torch.sum(\n",
    "    torch.square(\n",
    "        torch.einsum('ji,jk->ik', data_X, data_Y)\n",
    "    )\n",
    ")\n",
    "print(tr_sumsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.9073e-06, 0.0000e+00,\n",
      "        4.7684e-07], device='cuda:1')\n",
      "tensor([10.3022, 11.7083,  4.3699,  ..., 24.5278,  6.1498,  5.9414],\n",
      "       device='cuda:1')\n",
      "tensor([10.3022, 11.7083,  4.3699,  ..., 24.5278,  6.1498,  5.9414],\n",
      "       device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "# diag Phi verification\n",
    "data_X = torch.normal(0,1, [5000,9]).to(device)\n",
    "\n",
    "Phi = torch.einsum('ij,kj->ik', data_X, data_X)\n",
    "Phi_diag_matmul = torch.diagonal(Phi)\n",
    "\n",
    "Phi_diag_sumsq = torch.sum( torch.square(data_X), axis = 1)\n",
    "print(Phi_diag_matmul - Phi_diag_sumsq)\n",
    "print(Phi_diag_matmul)\n",
    "print(Phi_diag_sumsq)\n",
    "\n",
    "#success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:1')\n",
      "tensor(406992.8750, device='cuda:1')\n",
      "tensor(406992.8750, device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "# tr Phi diag Psi verification\n",
    "data_X = torch.normal(0,1, [5000,9]).to(device)\n",
    "data_Y = torch.normal(0,1, [5000,9]).to(device)\n",
    "\n",
    "\n",
    "Phi = torch.einsum('ij,kj->ik', data_X, data_X)\n",
    "Psi = torch.einsum('ij,kj->ik', data_Y, data_Y)\n",
    "\n",
    "trPhiDiagPsi_matmul = torch.trace(\n",
    "torch.matmul(\n",
    "    Phi,\n",
    "    torch.diag(torch.diagonal(Psi))\n",
    "))\n",
    " \n",
    "\n",
    "trPhiDiagPsi_sumsq = torch.inner(\n",
    "    torch.sum( torch.square(data_X), axis = 1),\n",
    "    torch.sum( torch.square(data_Y), axis = 1)\n",
    ")\n",
    "\n",
    "print(trPhiDiagPsi_matmul - trPhiDiagPsi_sumsq)\n",
    "print(trPhiDiagPsi_matmul)\n",
    "print(trPhiDiagPsi_sumsq)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-46376.3125, device='cuda:1')\n",
      "tensor(-46376.3750, device='cuda:1')\n",
      "tensor(0.0625, device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "#tr phi tilde psi tilde verification\n",
    "data_X = torch.normal(0,1, [5000,9]).to(device)\n",
    "data_Y = torch.normal(0,1, [5000,9]).to(device)\n",
    "\n",
    "Phi = torch.einsum('ij,kj->ik', data_X, data_X)\n",
    "Psi = torch.einsum('ij,kj->ik', data_Y, data_Y)\n",
    "Phi = Phi.fill_diagonal_(0.0)\n",
    "Psi = Psi.fill_diagonal_(0.0)\n",
    "tr_phi_tilde_psi_tilde_matmul = torch.trace( torch.matmul(Phi, Psi) )\n",
    "tr_phi_tilde_psi_tilde_sq = torch.sum(\n",
    "    torch.square(\n",
    "        torch.einsum('ji,jk->ik', data_X, data_Y)\n",
    "    )\n",
    ")- torch.inner(\n",
    "    torch.sum( torch.square(data_X), axis = 1),\n",
    "    torch.sum( torch.square(data_Y), axis = 1)\n",
    ")\n",
    "print(tr_phi_tilde_psi_tilde_matmul)\n",
    "print(tr_phi_tilde_psi_tilde_sq)\n",
    "print(tr_phi_tilde_psi_tilde_matmul - tr_phi_tilde_psi_tilde_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:18\u001b[0;36m\u001b[0m\n\u001b[0;31m    Un = 4 * onePhioneonePsione\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "    \n",
    "    #matrices\n",
    "    \n",
    "\n",
    "    one = torch.ones(n, 1).to(self.cuda_device)\n",
    "    oneT = torch.transpose(one, 0, 1)\n",
    "\n",
    "        PhiPsi = torch.matmul(Phi, Psi)\n",
    "        trPhiPsi = torch.trace(PhiPsi)\n",
    "        \n",
    "        onePhiPsiOne = torch.matmul(oneT, torch.matmul(PhiPsi, one))\n",
    "\n",
    "        onePhione = torch.matmul(oneT, torch.matmul(Phi, one))\n",
    "        onePsione = torch.matmul(oneT, torch.matmul(Psi, one))\n",
    "        onePhioneonePsione = torch.matmul(onePhione, onePsione)\n",
    "\n",
    " \n",
    "\n",
    "   Un = 4 * onePhioneonePsione\n",
    "   - ( 8 * (n-1) ) * onePhiPsiOne\n",
    "   + ( 4 * (n - 1) * (n - 2) ) * trPhiPsi     \n",
    "        \n",
    "    return(Un/n_four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_allocated(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = torch.matmul(data_X, torch.transpose(data_X, 0, 1))\n",
    "X_2 = torch.einsum('ij,kj->ik', data_X, data_X)\n",
    "Phi = torch.einsum('ij,kj->ik', data_X, data_X)\n",
    "    Psi = torch.einsum('ij,kj->ik', data_Y, data_Y)\n",
    "    Phi = Phi.fill_diagonal_(0.0)\n",
    "    Psi = Psi.fill_diagonal_(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "term by term comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5862e+08]], device='cuda:1')\n",
      "tensor([[-116701.6250]], device='cuda:1')\n",
      "tensor(-43602.1914, device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "data_X = torch.normal(0,1, [5000,9]).to(device)\n",
    "data_Y = torch.normal(0,1, [5000,9]).to(device)\n",
    "n = data_X.size(dim=0)\n",
    "\n",
    "# naive\n",
    "Phi = torch.matmul(data_X, torch.transpose(data_X, 0, 1))\n",
    "Psi = torch.matmul(data_Y, torch.transpose(data_Y, 0, 1))\n",
    "\n",
    "Phi = Phi.fill_diagonal_(0.0)\n",
    "Psi = Psi.fill_diagonal_(0.0)\n",
    "\n",
    "one = torch.ones(n, 1).to(device)\n",
    "oneT = torch.transpose(one, 0, 1)\n",
    "\n",
    "PhiPsi = torch.matmul(Phi, Psi)\n",
    "trPhiPsi = torch.trace(PhiPsi)\n",
    "onePhiPsiOne = torch.matmul(oneT, torch.matmul(PhiPsi, one))\n",
    "\n",
    "onePhione = torch.matmul(oneT, torch.matmul(Phi, one))\n",
    "onePsione = torch.matmul(oneT, torch.matmul(Psi, one))\n",
    "onePhioneonePsione = torch.matmul(onePhione, onePsione)\n",
    "print(onePhioneonePsione)\n",
    "print(onePhiPsiOne)\n",
    "print(trPhiPsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.5863e+08, device='cuda:1')\n",
      "tensor(-116707.6406, device='cuda:1')\n",
      "tensor(-43602.1250, device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "#data_X = torch.normal(0,1, [500000,9]).to(device)\n",
    "#data_Y = torch.normal(0,1, [500000,9]).to(device)\n",
    "X_row_sum = torch.sum(data_X, axis = 0)\n",
    "Y_row_sum = torch.sum(data_Y, axis = 0)\n",
    "phi_psi = torch.einsum('ji,jk->ik', data_X, data_Y)\n",
    "diag_Phi = torch.sum(torch.square(data_X), axis = 1)\n",
    "diag_Psi = torch.sum(torch.square(data_Y), axis = 1)\n",
    "#rowsum_Phi = torch.matmul(X_row_sum, torch.transpose(data_X, 0, 1) )\n",
    "rowsum_Phi = torch.einsum('i,ji -> j', X_row_sum, data_X)\n",
    "#rowsum_Psi = torch.matmul(data_Y, Y_row_sum)\n",
    "rowsum_Psi = torch.einsum('ij, j -> i', data_Y, Y_row_sum)\n",
    "\n",
    "#1. one term\n",
    "one_Phi_one = torch.inner(X_row_sum, X_row_sum)\n",
    "one_Psi_one = torch.inner(Y_row_sum, Y_row_sum)\n",
    "    \n",
    "tr_Phi = torch.sum(torch.square(data_X))\n",
    "tr_Psi = torch.sum(torch.square(data_Y))\n",
    "    \n",
    "one_Phi_tilde_one = one_Phi_one - tr_Phi\n",
    "one_Psi_tilde_one = one_Psi_one - tr_Psi\n",
    "    \n",
    "onePhioneonePsione = one_Phi_tilde_one * one_Psi_tilde_one\n",
    "print(onePhioneonePsione)\n",
    "\n",
    "    #2. one one term\n",
    "onePhiPsiOne = torch.matmul(\n",
    "    torch.matmul(X_row_sum, phi_psi),\n",
    "    Y_row_sum\n",
    "    )    + torch.inner(diag_Phi, diag_Psi)-torch.inner(rowsum_Phi, diag_Psi)-torch.inner(diag_Phi, rowsum_Psi)\n",
    "print(onePhiPsiOne)\n",
    "\n",
    "    \n",
    "    \n",
    "    #3. trace term\n",
    "trPhiPsi = torch.sum( torch.square(phi_psi) ) - torch.inner(\n",
    "        torch.sum( torch.square(data_X), axis = 1),\n",
    "        torch.sum( torch.square(data_Y), axis = 1)\n",
    "    )\n",
    "print(trPhiPsi)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.5477,  0.8468, -2.0360,  ...,  0.9780, -0.3794, -0.9752],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_row_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[55754756.]], device='cuda:1')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onePhioneonePsione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    n_four = n * (n-1) * (n-2) * (n-3)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def u_stat_indep_matrix_efficient(self, data_X, data_Y):\n",
    "    #scalars\n",
    "    n = data_X.size(dim = 0)\n",
    "    n_four = n * (n-1) * (n-2) * (n-3)\n",
    "\n",
    "    X_row_sum = torch.sum(data_X, axis = 0)\n",
    "    Y_row_sum = torch.sum(data_Y, axis = 0)\n",
    "    phi_psi = torch.einsum('ji,jk->ik', data_X, data_Y)\n",
    "    diag_Phi = torch.sum(torch.square(data_X), axis = 1)\n",
    "    diag_Psi = torch.sum(torch.square(data_Y), axis = 1)\n",
    "\n",
    "    #1. one term\n",
    "    one_Phi_one = torch.inner(X_row_sum, X_row_sum)\n",
    "    one_Psi_one = torch.inner(Y_row_sum, Y_row_sum)\n",
    "    \n",
    "    tr_Phi = torch.sum(torch.square(data_X))\n",
    "    tr_Psi = torch.sum(torch.square(data_Y))\n",
    "    \n",
    "    one_Phi_tilde_one = one_Phi_one - tr_Phi\n",
    "    one_Psi_tilde_one = one_Psi_one - tr_Psi\n",
    "    \n",
    "    onePhioneonePsione = one_Phi_tilde_one * one_Psi_tilde_one\n",
    "    print(onePhioneonePsione)\n",
    "    \n",
    "    #2. one one term\n",
    "    one_Phi_Psi_one = \n",
    "    torch.matmul(\n",
    "        torch.matmul(X_row_sum, phi_psi),\n",
    "        Y_row_sum\n",
    "    )    \n",
    "    + torch.inner(diag_Phi, diag_Psi)\n",
    "    - torch.inner(rowsum_Phi, diag_Psi)\n",
    "    - torch.inner(diag_Phi, rowsum_Psi)\n",
    "    \n",
    "    \n",
    "    #3. trace term\n",
    "    tr_phi_tilde_psi_tilde = torch.sum( torch.square(phi_psi) ) - torch.inner(\n",
    "        torch.sum( torch.square(data_X), axis = 1),\n",
    "        torch.sum( torch.square(data_Y), axis = 1)\n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    " \n",
    "\n",
    "   Un = 4 * onePhioneonePsione\n",
    "   - ( 16 + (8 * (n-3)) ) * onePhiPsiOne\n",
    "   + ( 8 + (8 * (n-3))  + (4 * (n-3)*(n-2)) ) * trPhiPsi     \n",
    "        \n",
    "    return(Un/n_four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def u_stat_indep_original(self, data_X, data_Y):\n",
    "        n = data_X.size(dim = 0)\n",
    "        print(f\"number of calculation = {2*scipy.special.comb(n,4) }\")\n",
    "        n_four = n * (n-1) * (n-2) * (n-3)\n",
    "        U_statistic = 0\n",
    "        for i in range(n):\n",
    "            set_j = set(range(n)) - {i}\n",
    "            for j in set_j:\n",
    "                set_k = set_j - {j}\n",
    "                for k in set_k:\n",
    "                    set_r = set_k - {k}\n",
    "                    for r in set_r:\n",
    "                        comb = [i,j,k,r]\n",
    "                        U_statistic = U_statistic + (\n",
    "                            self.kernel_indep(data_X[comb,]) * self.kernel_indep(data_Y[comb,])\n",
    "                        )/n_four\n",
    "        return(U_statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  #original form\n",
    "   #Un = (\n",
    "   #  4 * (onePhioneonePsione - 4 * onePhiPsiOne + 2 * trPhiPsi)\n",
    "   # - 8 * (n-3) *(onePhiPsiOne - trPhiPsi)\n",
    "   # + 4 * (n-3)*(n-2) * trPhiPsi\n",
    "   # )\n",
    "\n",
    "   # six terms\n",
    "   #Un = 4 * onePhioneonePsione\n",
    "   #- 16 * onePhiPsiOne\n",
    "   #+ 8  * trPhiPsi\n",
    "   #- 8 * (n-3) * onePhiPsiOne\n",
    "   #+ 8 * (n-3) * trPhiPsi\n",
    "   #+ 4 * (n-3)*(n-2) * trPhiPsi\n",
    "\n",
    "   # aggregate\n",
    "   # Un = 4 * onePhioneonePsione\n",
    "   # - ( 16 + (8 * (n-3)) ) * onePhiPsiOne\n",
    "   # + ( 8 + (8 * (n-3))  + (4 * (n-3)*(n-2)) ) * trPhiPsi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
